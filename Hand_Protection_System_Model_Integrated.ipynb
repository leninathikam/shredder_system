{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ae57130",
   "metadata": {},
   "source": [
    "# Hand Protection System for Shredder - Model Integration\n",
    "\n",
    "This notebook integrates the SSD MobileNet model and other utility scripts for real-time hand detection and safety alerts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b669d0b",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "Install all required libraries and ensure TensorFlow 2.x is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6764aa7-b503-4f49-a87c-17e03721eed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda activate shredder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "028a6709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting absl-py==0.7.1 (from -r requirements.txt (line 1))\n",
      "  Using cached absl-py-0.7.1.tar.gz (99 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [6 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"C:\\Users\\lenin\\AppData\\Local\\Temp\\pip-install-cc7ijhz_\\absl-py_3509d4fbe6134d5a8f0260b5fe4cd3b3\\setup.py\", line 34, in <module>\n",
      "      raise RuntimeError('Python version 2.7 or 3.4+ is required.')\n",
      "  RuntimeError: Python version 2.7 or 3.4+ is required.\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d823d16",
   "metadata": {},
   "source": [
    "## 2. Load Pre-trained SSD MobileNet Model\n",
    "\n",
    "Load the frozen inference graph, label map, and pipeline configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c0971d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the frozen inference graph...\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "NewRandomAccessFile failed to Create/Open: C:\\Users\\lenin\\Downloads\\New folder\\frozen_graphs\\ssd5_optimized_inference_graph.pb : The system cannot find the path specified.\r\n; No such process",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m             tf\u001b[38;5;241m.\u001b[39mimport_graph_def(od_graph_def, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m detection_graph\n\u001b[1;32m---> 20\u001b[0m detection_graph \u001b[38;5;241m=\u001b[39m load_model(frozen_graph_path)\n\u001b[0;32m     21\u001b[0m label_map \u001b[38;5;241m=\u001b[39m label_map_util\u001b[38;5;241m.\u001b[39mload_labelmap(label_map_path)\n\u001b[0;32m     22\u001b[0m categories \u001b[38;5;241m=\u001b[39m label_map_util\u001b[38;5;241m.\u001b[39mconvert_label_map_to_categories(label_map, max_num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, use_display_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[11], line 15\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(frozen_graph_path)\u001b[0m\n\u001b[0;32m     13\u001b[0m od_graph_def \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mGraphDef()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mGFile(frozen_graph_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[1;32m---> 15\u001b[0m     serialized_graph \u001b[38;5;241m=\u001b[39m fid\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     16\u001b[0m     od_graph_def\u001b[38;5;241m.\u001b[39mParseFromString(serialized_graph)\n\u001b[0;32m     17\u001b[0m     tf\u001b[38;5;241m.\u001b[39mimport_graph_def(od_graph_def, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:116\u001b[0m, in \u001b[0;36mFileIO.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    105\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the contents of a file as a string.\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03m  Starts reading from current position in file.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;124;03m    string if in string (regular) mode.\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preread_check()\n\u001b[0;32m    117\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    118\u001b[0m     length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:77\u001b[0m, in \u001b[0;36mFileIO._preread_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_check_passed:\n\u001b[0;32m     75\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mPermissionDeniedError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     76\u001b[0m                                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt open for reading\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_buf \u001b[38;5;241m=\u001b[39m _pywrap_file_io\u001b[38;5;241m.\u001b[39mBufferedInputStream(\n\u001b[0;32m     78\u001b[0m     compat\u001b[38;5;241m.\u001b[39mpath_to_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__name), \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m512\u001b[39m)\n",
      "\u001b[1;31mNotFoundError\u001b[0m: NewRandomAccessFile failed to Create/Open: C:\\Users\\lenin\\Downloads\\New folder\\frozen_graphs\\ssd5_optimized_inference_graph.pb : The system cannot find the path specified.\r\n; No such process"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from utils import label_map_util\n",
    "\n",
    "# Paths to the model and label map\n",
    "frozen_graph_path = r\"C:\\Users\\lenin\\Downloads\\New folder\\frozen_graphs\\ssd5_optimized_inference_graph.pb\"  # Replace with the correct frozen graph\n",
    "label_map_path = r\"C:\\Users\\lenin\\Downloads\\New folder\\frozen_graphs\\Glove_label_map.pbtxt\"  # Replace with the correct label map\n",
    "\n",
    "# Load the model\n",
    "def load_model(frozen_graph_path):\n",
    "    print(\"Loading the frozen inference graph...\")\n",
    "    detection_graph = tf.Graph()\n",
    "    with detection_graph.as_default():\n",
    "        od_graph_def = tf.compat.v1.GraphDef()\n",
    "        with tf.io.gfile.GFile(frozen_graph_path, 'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(od_graph_def, name='')\n",
    "    return detection_graph\n",
    "\n",
    "detection_graph = load_model(frozen_graph_path)\n",
    "label_map = label_map_util.load_labelmap(label_map_path)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=2, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "print(\"Model and label map loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323fa3e5",
   "metadata": {},
   "source": [
    "## 3. Safety Lines and Alerts\n",
    "\n",
    "Draw safety lines and integrate alert mechanisms for boundary violations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3719e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "from utils import orien_lines, alertcheck\n",
    "\n",
    "def display_safety_lines(image, orientation=\"bt\", perc1=15, perc2=30):\n",
    "    line_pos = orien_lines.drawsafelines(image, orientation, perc1, perc2)\n",
    "    return image, line_pos\n",
    "\n",
    "def process_alerts(image, p1, p2, line_position, orientation):\n",
    "    alert_triggered = alertcheck.drawboxtosafeline(image, p1, p2, line_position, orientation)\n",
    "    return alert_triggered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e59c80",
   "metadata": {},
   "source": [
    "## 4. Real-Time Detection\n",
    "\n",
    "Run the SSD MobileNet model for real-time hand detection, display safety lines, and trigger alerts if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad14fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def real_time_detection():\n",
    "    score_thresh = 0.5\n",
    "    video_stream = cv2.VideoCapture(0)\n",
    "\n",
    "    with detection_graph.as_default():\n",
    "        with tf.compat.v1.Session(graph=detection_graph) as sess:\n",
    "            while True:\n",
    "                ret, frame = video_stream.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                # Preprocess image\n",
    "                im_height, im_width, _ = frame.shape\n",
    "                image_np_expanded = np.expand_dims(frame, axis=0)\n",
    "\n",
    "                # Get tensors\n",
    "                image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "                detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "                detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "                detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "\n",
    "                # Run detection\n",
    "                (boxes, scores, classes) = sess.run(\n",
    "                    [detection_boxes, detection_scores, detection_classes],\n",
    "                    feed_dict={image_tensor: image_np_expanded})\n",
    "\n",
    "                # Draw safety lines\n",
    "                frame, line_position = display_safety_lines(frame, \"bt\")\n",
    "\n",
    "                # Draw boxes and process alerts\n",
    "                for i in range(boxes.shape[1]):\n",
    "                    if scores[0][i] > score_thresh:\n",
    "                        box = boxes[0][i]\n",
    "                        ymin, xmin, ymax, xmax = box\n",
    "                        p1 = (int(xmin * im_width), int(ymin * im_height))\n",
    "                        p2 = (int(xmax * im_width), int(ymax * im_height))\n",
    "                        process_alerts(frame, p1, p2, line_position, \"bt\")\n",
    "                        cv2.rectangle(frame, p1, p2, (0, 255, 0), 2)\n",
    "\n",
    "                # Display frame\n",
    "                cv2.imshow(\"Real-Time Detection\", frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                    break\n",
    "\n",
    "    video_stream.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "real_time_detection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce6c17d-b079-4adb-99b7-060473f8cec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def save_hand_detection_data(no_of_time_hand_detected, no_of_time_hand_crossed, file_path='result.xlsx'):\n",
    "    \"\"\"Save hand detection data to an Excel file.\"\"\"\n",
    "    today = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Check if the file exists\n",
    "    if os.path.exists(file_path):\n",
    "        # Load existing data\n",
    "        df = pd.read_excel(file_path)\n",
    "        if today in df['Date'].values:\n",
    "            # Update the existing row\n",
    "            df.loc[df['Date'] == today, 'Number of times hand detected'] += no_of_time_hand_detected\n",
    "            df.loc[df['Date'] == today, 'Number of times hand crossed'] += no_of_time_hand_crossed\n",
    "        else:\n",
    "            # Append a new row\n",
    "            new_row = {\n",
    "                'Date': today,\n",
    "                'Number of times hand detected': no_of_time_hand_detected,\n",
    "                'Number of times hand crossed': no_of_time_hand_crossed\n",
    "            }\n",
    "            df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    else:\n",
    "        # Create a new DataFrame if the file doesn't exist\n",
    "        df = pd.DataFrame({\n",
    "            'Date': [today],\n",
    "            'Number of times hand detected': [no_of_time_hand_detected],\n",
    "            'Number of times hand crossed': [no_of_time_hand_crossed]\n",
    "        })\n",
    "\n",
    "    # Save the data back to the file\n",
    "    df.to_excel(file_path, index=False)\n",
    "    print(f\"Data saved successfully to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012e816e-4e29-4a4c-b79d-50451df02e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_time_detection():\n",
    "    score_thresh = 0.5\n",
    "    video_stream = cv2.VideoCapture(0)\n",
    "\n",
    "    if not video_stream.isOpened():\n",
    "        print(\"Error: Cannot access the camera.\")\n",
    "        return\n",
    "\n",
    "    # Counters for detections and crossings\n",
    "    lst1 = []\n",
    "    lst2 = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_stream.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Cannot read from camera.\")\n",
    "            break\n",
    "\n",
    "        # Perform detection\n",
    "        input_tensor = tf.convert_to_tensor(frame)\n",
    "        input_tensor = input_tensor[tf.newaxis, ...]\n",
    "        detections = detection_model(input_tensor)\n",
    "\n",
    "        # Process detection results\n",
    "        boxes = detections['detection_boxes'][0].numpy()\n",
    "        scores = detections['detection_scores'][0].numpy()\n",
    "        classes = detections['detection_classes'][0].numpy().astype(int)\n",
    "\n",
    "        # Draw detections and safety lines\n",
    "        frame, line_position = display_safety_lines(frame, \"bt\")\n",
    "        for i, box in enumerate(boxes):\n",
    "            if scores[i] > score_thresh:\n",
    "                ymin, xmin, ymax, xmax = box\n",
    "                p1 = (int(xmin * frame.shape[1]), int(ymin * frame.shape[0]))\n",
    "                p2 = (int(xmax * frame.shape[1]), int(ymax * frame.shape[0]))\n",
    "                detection_result = process_alerts(frame, p1, p2, line_position, \"bt\")\n",
    "                lst1.append(detection_result)  # Track hand crossing\n",
    "                lst2.append(1)  # Track hand detection\n",
    "                cv2.rectangle(frame, p1, p2, (0, 255, 0), 2)\n",
    "\n",
    "        # Display frame\n",
    "        cv2.imshow(\"Real-Time Detection\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    video_stream.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Calculate hand detection and crossings\n",
    "    def count_occurrences(lst):\n",
    "        return sum(1 for i, val in enumerate(lst) if val == 1 and (i == 0 or lst[i - 1] == 0))\n",
    "\n",
    "    no_of_time_hand_detected = count_occurrences(lst2)\n",
    "    no_of_time_hand_crossed = count_occurrences(lst1)\n",
    "\n",
    "    # Save data to Excel\n",
    "    save_hand_detection_data(no_of_time_hand_detected, no_of_time_hand_crossed)\n",
    "    print(\"Data saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3aeea320-7bd3-46d4-af3a-43de86f70b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 21:28:16.960441: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-01 21:28:18.769332: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lenin\\Downloads\\New _folder\\hand_detection.py\", line 6, in <module>\n",
      "    from utils import detector_utils as detector_utils\n",
      "  File \"C:\\Users\\lenin\\Downloads\\New _folder\\utils\\detector_utils.py\", line 23, in <module>\n",
      "    label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lenin\\Downloads\\New _folder\\utils\\label_map_util.py\", line 116, in load_labelmap\n",
      "    with tf.gfile.GFile(path, 'r') as fid:\n",
      "         ^^^^^^^^\n",
      "AttributeError: module 'tensorflow' has no attribute 'gfile'. Did you mean: 'fill'?\n"
     ]
    }
   ],
   "source": [
    "!python hand_detection.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629a14d5-af0b-45db-8706-92bd502e503d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8583cf8d-f3bd-4468-8e88-d630ddb99d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in c:\\users\\lenin\\anaconda3\\lib\\site-packages (6.28.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\lenin\\anaconda3\\lib\\site-packages (from ipykernel) (0.2.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\lenin\\anaconda3\\lib\\site-packages (from ipykernel) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\lenin\\anaconda3\\lib\\site-packages (from ipykernel) (8.25.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\lenin\\anaconda3\\lib\\site-packages (from ipykernel) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\lenin\\anaconda3\\lib\\site-packages (from ipykernel) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\lenin\\anaconda3\\lib\\site-packages (from ipykernel) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\lenin\\anaconda3\\lib\\site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenin\\anaconda3\\lib\\site-packages (from ipykernel) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\lenin\\anaconda3\\lib\\site-packages (from ipykernel) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\lenin\\anaconda3\\lib\\site-packages (from ipykernel) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\lenin\\anaconda3\\lib\\site-packages (from ipykernel) (6.4.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\lenin\\anaconda3\\lib\\site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: decorator in c:\\users\\lenin\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\lenin\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.18.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\lenin\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\lenin\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\lenin\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenin\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenin\\anaconda3\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\lenin\\anaconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\lenin\\anaconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (305.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\lenin\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\lenin\\anaconda3\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
      "Requirement already satisfied: executing in c:\\users\\lenin\\anaconda3\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\lenin\\anaconda3\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\lenin\\anaconda3\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.2)\n"
     ]
    }
   ],
   "source": [
    "!.\\venv\\Scripts\\activate\n",
    "!pip install ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c9b49f3-d5cb-40cb-81d5-edf6f0b0c545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed kernelspec shredder in C:\\Users\\lenin\\AppData\\Roaming\\jupyter\\kernels\\shredder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "!python -m ipykernel install --user --name=shredder --display-name \"shredder\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ae590b0-3388-499f-9bab-0e3603913c55",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'gfile'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\Downloads\\New _folder\\hand_detection.py:6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VideoStream\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m detector_utils \u001b[38;5;28;01mas\u001b[39;00m detector_utils\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m date\n",
      "File \u001b[1;32m~\\Downloads\\New _folder\\utils\\detector_utils.py:23\u001b[0m\n\u001b[0;32m     21\u001b[0m NUM_CLASSES \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# load label map using utils provided by tensorflow object detection api\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m label_map \u001b[38;5;241m=\u001b[39m label_map_util\u001b[38;5;241m.\u001b[39mload_labelmap(PATH_TO_LABELS)\n\u001b[0;32m     24\u001b[0m categories \u001b[38;5;241m=\u001b[39m label_map_util\u001b[38;5;241m.\u001b[39mconvert_label_map_to_categories(\n\u001b[0;32m     25\u001b[0m     label_map, max_num_classes\u001b[38;5;241m=\u001b[39mNUM_CLASSES, use_display_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     26\u001b[0m category_index \u001b[38;5;241m=\u001b[39m label_map_util\u001b[38;5;241m.\u001b[39mcreate_category_index(categories)\n",
      "File \u001b[1;32m~\\Downloads\\New _folder\\utils\\label_map_util.py:116\u001b[0m, in \u001b[0;36mload_labelmap\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_labelmap\u001b[39m(path):\n\u001b[0;32m    109\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads label map proto.\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;124;03m      a StringIntLabelMapProto\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mGFile(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[0;32m    117\u001b[0m         label_map_string \u001b[38;5;241m=\u001b[39m fid\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    118\u001b[0m         label_map \u001b[38;5;241m=\u001b[39m string_int_label_map_pb2\u001b[38;5;241m.\u001b[39mStringIntLabelMap()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'gfile'"
     ]
    }
   ],
   "source": [
    "%run hand_detection.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8653b464-ff47-423d-a6f3-b319b0004178",
   "metadata": {},
   "outputs": [],
   "source": [
    "!.\\venv\\Scripts\\activate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "987d4b08-0a39-4d31-9298-c136530c3848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow==1.15 (from versions: 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0)\n",
      "ERROR: No matching distribution found for tensorflow==1.15\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2777c6-cce6-4fd0-b54e-c61bb6826fec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
